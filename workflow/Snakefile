# Python standard library
from os.path import join
from os import listdir
import os, sys

# 3rd party imports from pypi
from snakemake.workflow import workflow as wf_api
from snakemake.utils import R

# Local imports
from scripts.common import (
    allocated,
    provided, 
    references,
    str_bool
)


# Global workflow variables
configfile: 'config.json'                      # Generated from user input and config/*.json
workpath = config['project']['workpath']       # Pipeline's output directory
tmpdir   = config['options']['tmp_dir']        # Temporary directory
genome   = config['options']['genome']         # Reference genome of a set of samples
samples  = config['samples']                   # List containing basename of samples

# Analysis options
min_read_length = config['options']['min_read_length']  # Min length of a trimmed read (discarded if less)
max_read_length = config['options']['max_read_length']  # Max length of a trimmed read (cropped if greater)

# Read in resource information,
# containing information about 
# threads, mem, walltimes, etc.
# TODO: Add handler for when the
# mode is set to local.
with open(join(workpath, 'config', 'cluster.json')) as fh:
    cluster = json.load(fh)

# Final ouput files of the pipeline
rule all:
    input:
        # Adpapter trimming rule,
        # @imported from `rule fastp` in rules/trim.smk
        expand(
            join(workpath, "trim", "{sample}_trimmed.fastq.gz"), 
            sample=samples
        ),
        # Convert trimmed FastQ to FASTA,
        # @imported from `rule seqkit_fq2fa` in rules/trim.smk
        expand(
            join(workpath,"trim", "{sample}_trimmed_cleaned.fa"),
            sample=samples
        ),
        # Map reads to the reference genome,
        # @imported from `rule mirdeep2_mapper` in rules/align.smk
        expand(
            join(workpath, "mirdeep2", "mapper", "{sample}_mapped.arf"),
            sample=samples
        ),
        expand(
            join(workpath, "mirdeep2", "mapper", "{sample}", "{sample}.mapper.tsv"),
            sample=samples
        ),
        # Gather mirdeep2 mapper statistics
        # @imported from `rule mirdeep2_gather_mapper_statistics` in rules/align.smk
        join(workpath, "mirdeep2", "mapper", "mirdeep2.mapper.tsv"),
        # Detect known and novel miRNAs,
        # @imported from `rule mirdeep2_run` in rules/quant.smk
        expand(
            join(workpath, "mirdeep2", "counts", "{sample}_miRNA_expressed.tsv"),
            sample=samples
        ),
        # Find average mature miRNA expression,
        # @imported from `rule mature_expression` in rules/quant.smk
        expand(
            join(workpath, "mirdeep2", "counts", "{sample}_mature_miRNA_expression.tsv"),
            sample=samples
        ),
        # Create a mature miRNA counts matrix,
        # @imported from `rule merge_results` in rules/quant.smk
        join(workpath, "mirdeep2", "counts", "miRDeep2_mature_miRNA_counts.tsv"),
        # Quality-control step to assess sequencing 
        # quality of raw and trimmed FastQ files,
        # @imported from `rule fastqc_*` in rules/qc.smk
        expand(
            join(workpath, "fastqc", "{sample}.R1_fastqc.zip"),
            sample=samples
        ),
        expand(
            join(workpath, "fastqc", "{sample}_trimmed_fastqc.zip"),
            sample=samples
        ),
        # Aggregated quality-control report,
        # @imported from `rule multiqc` in rules/qc.smk
        join(workpath, "reports", "multiqc_report.html"),


# Import rules
include: join("rules", "common.smk")
include: join("rules", "hooks.smk")
include: join("rules", "trim.smk")
include: join("rules", "align.smk")
include: join("rules", "quant.smk")
include: join("rules", "qc.smk")